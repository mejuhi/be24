{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the saved data pickle file\n",
    "df_stocks = pd.read_pickle('DataGathered/ProcesssedData/pickled_ten_year_filtered_lead_para_GSPC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>1417.280005</td>\n",
       "      <td>2.728776e+09</td>\n",
       "      <td>. Estimates of Iraqi Civilian Deaths. Romania ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>1416.939991</td>\n",
       "      <td>3.078968e+09</td>\n",
       "      <td>. For Dodd, Wall Street Looms Large. Ford's Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>1416.599976</td>\n",
       "      <td>3.429160e+09</td>\n",
       "      <td>. Ethics Changes Proposed for House Trips, K S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>1418.339966</td>\n",
       "      <td>3.004460e+09</td>\n",
       "      <td>. I Feel Bad About My Face. Bush Recycles the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>1409.709961</td>\n",
       "      <td>2.919400e+09</td>\n",
       "      <td>. Macworld Bingo. Anti-Surge Protests Against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-06</th>\n",
       "      <td>1410.753296</td>\n",
       "      <td>2.867380e+09</td>\n",
       "      <td>. In da Car at Dakar. The Macworld-C.E.S. Conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-07</th>\n",
       "      <td>1411.796631</td>\n",
       "      <td>2.815360e+09</td>\n",
       "      <td>. BitTorrent Comes to the Television. LG&amp;#8217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>1412.839966</td>\n",
       "      <td>2.763340e+09</td>\n",
       "      <td>. That R2 Unit Is a Real Bargain. HDTV Heavy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>1412.109985</td>\n",
       "      <td>3.038380e+09</td>\n",
       "      <td>. The iPhone Rumors Are Right&amp;#8230;Finally. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>1414.849976</td>\n",
       "      <td>2.764660e+09</td>\n",
       "      <td>. A Ride in a Gaming Chair. More iPhone Fun Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-11</th>\n",
       "      <td>1423.819946</td>\n",
       "      <td>2.857870e+09</td>\n",
       "      <td>. Accounting Games. The Good Old-Fashioned Pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-12</th>\n",
       "      <td>1430.729980</td>\n",
       "      <td>2.686480e+09</td>\n",
       "      <td>. More on Black. Best and Worst of Show. Blogt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-13</th>\n",
       "      <td>1431.022491</td>\n",
       "      <td>2.664742e+09</td>\n",
       "      <td>. Sunday's Breakfast Menu: Jan. 14. 2008: Huck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-14</th>\n",
       "      <td>1431.315002</td>\n",
       "      <td>2.643005e+09</td>\n",
       "      <td>. New Angle on the New Ferrari. Revisiting Aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-15</th>\n",
       "      <td>1431.607513</td>\n",
       "      <td>2.621268e+09</td>\n",
       "      <td>. Those Heroes of Darfur. Tightwads and Spendt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-16</th>\n",
       "      <td>1431.900024</td>\n",
       "      <td>2.599530e+09</td>\n",
       "      <td>. Already an iPhone Twin?. Blogtalk: Obama's P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-17</th>\n",
       "      <td>1430.619995</td>\n",
       "      <td>2.690270e+09</td>\n",
       "      <td>. How Gentlemen Disagree. The Price of Oil in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>1426.369995</td>\n",
       "      <td>2.822430e+09</td>\n",
       "      <td>. An Epidemic of Misunderstanding About Childr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>1430.500000</td>\n",
       "      <td>2.777480e+09</td>\n",
       "      <td>. Raikkonen's Red Tank. The Week That Was. Nip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-20</th>\n",
       "      <td>1427.983317</td>\n",
       "      <td>2.698360e+09</td>\n",
       "      <td>. Talking to Iran. 2008 Like It's All Weekend:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-21</th>\n",
       "      <td>1425.466634</td>\n",
       "      <td>2.619240e+09</td>\n",
       "      <td>. All the Presidents' Libraries. Bruce McLaren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-22</th>\n",
       "      <td>1422.949951</td>\n",
       "      <td>2.540120e+09</td>\n",
       "      <td>. Moguls Arrive, One Eye on the Sky. The View ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-23</th>\n",
       "      <td>1427.989990</td>\n",
       "      <td>2.975070e+09</td>\n",
       "      <td>. Google’s High-Octane Mixer. Davos Moment: Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-24</th>\n",
       "      <td>1440.130005</td>\n",
       "      <td>2.783180e+09</td>\n",
       "      <td>. Giuliani Is Expected to Sell His Investment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-25</th>\n",
       "      <td>1423.900024</td>\n",
       "      <td>2.994330e+09</td>\n",
       "      <td>. Hedge Fund Money to Play Role in Political R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-26</th>\n",
       "      <td>1422.180054</td>\n",
       "      <td>2.626620e+09</td>\n",
       "      <td>. Google Guys Aren’t Writing Off Old Media. A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-27</th>\n",
       "      <td>1421.660034</td>\n",
       "      <td>2.661240e+09</td>\n",
       "      <td>. Crowd Turns Out for Blair’s Not-Quite-Farewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-28</th>\n",
       "      <td>1421.140015</td>\n",
       "      <td>2.695860e+09</td>\n",
       "      <td>. C.E.O.’s Drive On Thin Ice. Davos 2007 in Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-29</th>\n",
       "      <td>1420.619995</td>\n",
       "      <td>2.730480e+09</td>\n",
       "      <td>. Social Entrepreneurs. \"Sunday Morning\" on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-30</th>\n",
       "      <td>1428.819946</td>\n",
       "      <td>2.706250e+09</td>\n",
       "      <td>. Our Secret Stash of Oil. Baker and Hamilton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>2191.949951</td>\n",
       "      <td>3.779500e+09</td>\n",
       "      <td>. Silicon Valley Chiefs Notably Absent From Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-03</th>\n",
       "      <td>2196.203288</td>\n",
       "      <td>3.818077e+09</td>\n",
       "      <td>. Trump, Taiwan and China: The Controversy, Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-04</th>\n",
       "      <td>2200.456624</td>\n",
       "      <td>3.856653e+09</td>\n",
       "      <td>. Hunting ‘Turr’ in Newfoundland’s Frigid Wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>2204.709961</td>\n",
       "      <td>3.895230e+09</td>\n",
       "      <td>. Trump’s Meeting With Al Gore Gives Environme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>2212.229980</td>\n",
       "      <td>3.855320e+09</td>\n",
       "      <td>. Senate Republican Leaders Vow to Begin Repea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>2241.350098</td>\n",
       "      <td>4.501820e+09</td>\n",
       "      <td>. Can Congress Lift the Presidential Conflict ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>2246.189941</td>\n",
       "      <td>4.200580e+09</td>\n",
       "      <td>. The Freaky Food Chain Behind Your Lobster Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-09</th>\n",
       "      <td>2259.530029</td>\n",
       "      <td>3.884480e+09</td>\n",
       "      <td>. Trump Spent Far Less Than Clinton, but Paid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-10</th>\n",
       "      <td>2258.673340</td>\n",
       "      <td>3.934490e+09</td>\n",
       "      <td>. As Turkey Cracks Down, Kurdish Mayors Pack B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>2257.816650</td>\n",
       "      <td>3.984500e+09</td>\n",
       "      <td>. I.M.F. Chief Heads to Trial; Fed Is Expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>2256.959961</td>\n",
       "      <td>4.034510e+09</td>\n",
       "      <td>. Pennsylvania and Wisconsin End Election Reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>2271.719971</td>\n",
       "      <td>3.857590e+09</td>\n",
       "      <td>. The Most Talked-About Debates of 2016. Wells...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>2253.280029</td>\n",
       "      <td>4.406970e+09</td>\n",
       "      <td>. Can Trump Get Tough With China?. The Oakland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>2262.030029</td>\n",
       "      <td>4.168200e+09</td>\n",
       "      <td>. Hispanic Surnames on the Rise in U.S. as Imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>2258.070068</td>\n",
       "      <td>5.920340e+09</td>\n",
       "      <td>. Vine, the Six-Second Video App, Is Not Quite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-17</th>\n",
       "      <td>2259.556722</td>\n",
       "      <td>5.029683e+09</td>\n",
       "      <td>. Trump’s Win Helps Carve a Path to Washington...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>2261.043375</td>\n",
       "      <td>4.139027e+09</td>\n",
       "      <td>. With Comic Book, Celebrities Pay Tribute to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>2262.530029</td>\n",
       "      <td>3.248370e+09</td>\n",
       "      <td>. Donald Trump and the C.I.A.. Vincent Viola, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>2270.760010</td>\n",
       "      <td>3.298780e+09</td>\n",
       "      <td>. Can Trump's Infrastructure Plan Work?. Volks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>2265.179932</td>\n",
       "      <td>2.852230e+09</td>\n",
       "      <td>. Совершенное орудие: как российская кибермощь...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>2260.959961</td>\n",
       "      <td>2.876320e+09</td>\n",
       "      <td>. New Ebola Vaccine Gives 100 Percent Protecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>2263.790039</td>\n",
       "      <td>2.020550e+09</td>\n",
       "      <td>. Flurry of Settlements Over Toxic Mortgages M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>2265.062500</td>\n",
       "      <td>2.012182e+09</td>\n",
       "      <td>. Jason Miller Backs Out of White House Commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>2266.334961</td>\n",
       "      <td>2.003815e+09</td>\n",
       "      <td>. Wielding Claims of ‘Fake News,’ Conservative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>2267.607422</td>\n",
       "      <td>1.995448e+09</td>\n",
       "      <td>. When One Party Has the Governor’s Mansion an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>2268.879883</td>\n",
       "      <td>1.987080e+09</td>\n",
       "      <td>. Should the U.S. Embassy Be Moved From Tel Av...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>2249.919922</td>\n",
       "      <td>2.392360e+09</td>\n",
       "      <td>. When Finding the Right Lawyer Seems Daunting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>2249.260010</td>\n",
       "      <td>2.336370e+09</td>\n",
       "      <td>. Does Empathy Guide or Hinder Moral Action?. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>2238.830078</td>\n",
       "      <td>2.670900e+09</td>\n",
       "      <td>. Shielding Seized Assets From Corruption’s Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>2238.830078</td>\n",
       "      <td>2.670900e+09</td>\n",
       "      <td>Terrorist Attack at Nightclub in Istanbul Kill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  close     adj close  \\\n",
       "2007-01-01  1417.280005  2.728776e+09   \n",
       "2007-01-02  1416.939991  3.078968e+09   \n",
       "2007-01-03  1416.599976  3.429160e+09   \n",
       "2007-01-04  1418.339966  3.004460e+09   \n",
       "2007-01-05  1409.709961  2.919400e+09   \n",
       "2007-01-06  1410.753296  2.867380e+09   \n",
       "2007-01-07  1411.796631  2.815360e+09   \n",
       "2007-01-08  1412.839966  2.763340e+09   \n",
       "2007-01-09  1412.109985  3.038380e+09   \n",
       "2007-01-10  1414.849976  2.764660e+09   \n",
       "2007-01-11  1423.819946  2.857870e+09   \n",
       "2007-01-12  1430.729980  2.686480e+09   \n",
       "2007-01-13  1431.022491  2.664742e+09   \n",
       "2007-01-14  1431.315002  2.643005e+09   \n",
       "2007-01-15  1431.607513  2.621268e+09   \n",
       "2007-01-16  1431.900024  2.599530e+09   \n",
       "2007-01-17  1430.619995  2.690270e+09   \n",
       "2007-01-18  1426.369995  2.822430e+09   \n",
       "2007-01-19  1430.500000  2.777480e+09   \n",
       "2007-01-20  1427.983317  2.698360e+09   \n",
       "2007-01-21  1425.466634  2.619240e+09   \n",
       "2007-01-22  1422.949951  2.540120e+09   \n",
       "2007-01-23  1427.989990  2.975070e+09   \n",
       "2007-01-24  1440.130005  2.783180e+09   \n",
       "2007-01-25  1423.900024  2.994330e+09   \n",
       "2007-01-26  1422.180054  2.626620e+09   \n",
       "2007-01-27  1421.660034  2.661240e+09   \n",
       "2007-01-28  1421.140015  2.695860e+09   \n",
       "2007-01-29  1420.619995  2.730480e+09   \n",
       "2007-01-30  1428.819946  2.706250e+09   \n",
       "...                 ...           ...   \n",
       "2016-12-02  2191.949951  3.779500e+09   \n",
       "2016-12-03  2196.203288  3.818077e+09   \n",
       "2016-12-04  2200.456624  3.856653e+09   \n",
       "2016-12-05  2204.709961  3.895230e+09   \n",
       "2016-12-06  2212.229980  3.855320e+09   \n",
       "2016-12-07  2241.350098  4.501820e+09   \n",
       "2016-12-08  2246.189941  4.200580e+09   \n",
       "2016-12-09  2259.530029  3.884480e+09   \n",
       "2016-12-10  2258.673340  3.934490e+09   \n",
       "2016-12-11  2257.816650  3.984500e+09   \n",
       "2016-12-12  2256.959961  4.034510e+09   \n",
       "2016-12-13  2271.719971  3.857590e+09   \n",
       "2016-12-14  2253.280029  4.406970e+09   \n",
       "2016-12-15  2262.030029  4.168200e+09   \n",
       "2016-12-16  2258.070068  5.920340e+09   \n",
       "2016-12-17  2259.556722  5.029683e+09   \n",
       "2016-12-18  2261.043375  4.139027e+09   \n",
       "2016-12-19  2262.530029  3.248370e+09   \n",
       "2016-12-20  2270.760010  3.298780e+09   \n",
       "2016-12-21  2265.179932  2.852230e+09   \n",
       "2016-12-22  2260.959961  2.876320e+09   \n",
       "2016-12-23  2263.790039  2.020550e+09   \n",
       "2016-12-24  2265.062500  2.012182e+09   \n",
       "2016-12-25  2266.334961  2.003815e+09   \n",
       "2016-12-26  2267.607422  1.995448e+09   \n",
       "2016-12-27  2268.879883  1.987080e+09   \n",
       "2016-12-28  2249.919922  2.392360e+09   \n",
       "2016-12-29  2249.260010  2.336370e+09   \n",
       "2016-12-30  2238.830078  2.670900e+09   \n",
       "2016-12-31  2238.830078  2.670900e+09   \n",
       "\n",
       "                                                     articles  \n",
       "2007-01-01  . Estimates of Iraqi Civilian Deaths. Romania ...  \n",
       "2007-01-02  . For Dodd, Wall Street Looms Large. Ford's Lo...  \n",
       "2007-01-03  . Ethics Changes Proposed for House Trips, K S...  \n",
       "2007-01-04  . I Feel Bad About My Face. Bush Recycles the ...  \n",
       "2007-01-05  . Macworld Bingo. Anti-Surge Protests Against ...  \n",
       "2007-01-06  . In da Car at Dakar. The Macworld-C.E.S. Conf...  \n",
       "2007-01-07  . BitTorrent Comes to the Television. LG&#8217...  \n",
       "2007-01-08  . That R2 Unit Is a Real Bargain. HDTV Heavy. ...  \n",
       "2007-01-09  . The iPhone Rumors Are Right&#8230;Finally. P...  \n",
       "2007-01-10  . A Ride in a Gaming Chair. More iPhone Fun Fa...  \n",
       "2007-01-11  . Accounting Games. The Good Old-Fashioned Pla...  \n",
       "2007-01-12  . More on Black. Best and Worst of Show. Blogt...  \n",
       "2007-01-13  . Sunday's Breakfast Menu: Jan. 14. 2008: Huck...  \n",
       "2007-01-14  . New Angle on the New Ferrari. Revisiting Aff...  \n",
       "2007-01-15  . Those Heroes of Darfur. Tightwads and Spendt...  \n",
       "2007-01-16  . Already an iPhone Twin?. Blogtalk: Obama's P...  \n",
       "2007-01-17  . How Gentlemen Disagree. The Price of Oil in ...  \n",
       "2007-01-18  . An Epidemic of Misunderstanding About Childr...  \n",
       "2007-01-19  . Raikkonen's Red Tank. The Week That Was. Nip...  \n",
       "2007-01-20  . Talking to Iran. 2008 Like It's All Weekend:...  \n",
       "2007-01-21  . All the Presidents' Libraries. Bruce McLaren...  \n",
       "2007-01-22  . Moguls Arrive, One Eye on the Sky. The View ...  \n",
       "2007-01-23  . Google’s High-Octane Mixer. Davos Moment: Ho...  \n",
       "2007-01-24  . Giuliani Is Expected to Sell His Investment ...  \n",
       "2007-01-25  . Hedge Fund Money to Play Role in Political R...  \n",
       "2007-01-26  . Google Guys Aren’t Writing Off Old Media. A ...  \n",
       "2007-01-27  . Crowd Turns Out for Blair’s Not-Quite-Farewe...  \n",
       "2007-01-28  . C.E.O.’s Drive On Thin Ice. Davos 2007 in Re...  \n",
       "2007-01-29  . Social Entrepreneurs. \"Sunday Morning\" on th...  \n",
       "2007-01-30  . Our Secret Stash of Oil. Baker and Hamilton ...  \n",
       "...                                                       ...  \n",
       "2016-12-02  . Silicon Valley Chiefs Notably Absent From Tr...  \n",
       "2016-12-03  . Trump, Taiwan and China: The Controversy, Ex...  \n",
       "2016-12-04  . Hunting ‘Turr’ in Newfoundland’s Frigid Wate...  \n",
       "2016-12-05  . Trump’s Meeting With Al Gore Gives Environme...  \n",
       "2016-12-06  . Senate Republican Leaders Vow to Begin Repea...  \n",
       "2016-12-07  . Can Congress Lift the Presidential Conflict ...  \n",
       "2016-12-08  . The Freaky Food Chain Behind Your Lobster Di...  \n",
       "2016-12-09  . Trump Spent Far Less Than Clinton, but Paid ...  \n",
       "2016-12-10  . As Turkey Cracks Down, Kurdish Mayors Pack B...  \n",
       "2016-12-11  . I.M.F. Chief Heads to Trial; Fed Is Expected...  \n",
       "2016-12-12  . Pennsylvania and Wisconsin End Election Reco...  \n",
       "2016-12-13  . The Most Talked-About Debates of 2016. Wells...  \n",
       "2016-12-14  . Can Trump Get Tough With China?. The Oakland...  \n",
       "2016-12-15  . Hispanic Surnames on the Rise in U.S. as Imm...  \n",
       "2016-12-16  . Vine, the Six-Second Video App, Is Not Quite...  \n",
       "2016-12-17  . Trump’s Win Helps Carve a Path to Washington...  \n",
       "2016-12-18  . With Comic Book, Celebrities Pay Tribute to ...  \n",
       "2016-12-19  . Donald Trump and the C.I.A.. Vincent Viola, ...  \n",
       "2016-12-20  . Can Trump's Infrastructure Plan Work?. Volks...  \n",
       "2016-12-21  . Совершенное орудие: как российская кибермощь...  \n",
       "2016-12-22  . New Ebola Vaccine Gives 100 Percent Protecti...  \n",
       "2016-12-23  . Flurry of Settlements Over Toxic Mortgages M...  \n",
       "2016-12-24  . Jason Miller Backs Out of White House Commun...  \n",
       "2016-12-25  . Wielding Claims of ‘Fake News,’ Conservative...  \n",
       "2016-12-26  . When One Party Has the Governor’s Mansion an...  \n",
       "2016-12-27  . Should the U.S. Embassy Be Moved From Tel Av...  \n",
       "2016-12-28  . When Finding the Right Lawyer Seems Daunting...  \n",
       "2016-12-29  . Does Empathy Guide or Hinder Moral Action?. ...  \n",
       "2016-12-30  . Shielding Seized Assets From Corruption’s Cl...  \n",
       "2016-12-31  Terrorist Attack at Nightclub in Istanbul Kill...  \n",
       "\n",
       "[3653 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks['prices'] = df_stocks['adj close'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting the prices and articles\n",
    "df_stocks = df_stocks[['prices', 'articles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_stocks['articles'] = df_stocks['articles'].map(lambda x: x.lstrip('.-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>2728776000</td>\n",
       "      <td>Estimates of Iraqi Civilian Deaths. Romania a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>3078968000</td>\n",
       "      <td>For Dodd, Wall Street Looms Large. Ford's Los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>3429160000</td>\n",
       "      <td>Ethics Changes Proposed for House Trips, K St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>3004460000</td>\n",
       "      <td>I Feel Bad About My Face. Bush Recycles the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>2919400000</td>\n",
       "      <td>Macworld Bingo. Anti-Surge Protests Against M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-06</th>\n",
       "      <td>2867380000</td>\n",
       "      <td>In da Car at Dakar. The Macworld-C.E.S. Confl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-07</th>\n",
       "      <td>2815360000</td>\n",
       "      <td>BitTorrent Comes to the Television. LG&amp;#8217;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>2763340000</td>\n",
       "      <td>That R2 Unit Is a Real Bargain. HDTV Heavy. L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>3038380000</td>\n",
       "      <td>The iPhone Rumors Are Right&amp;#8230;Finally. Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>2764660000</td>\n",
       "      <td>A Ride in a Gaming Chair. More iPhone Fun Fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-11</th>\n",
       "      <td>2857870000</td>\n",
       "      <td>Accounting Games. The Good Old-Fashioned Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-12</th>\n",
       "      <td>2686480000</td>\n",
       "      <td>More on Black. Best and Worst of Show. Blogta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-13</th>\n",
       "      <td>2664742500</td>\n",
       "      <td>Sunday's Breakfast Menu: Jan. 14. 2008: Hucka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-14</th>\n",
       "      <td>2643005000</td>\n",
       "      <td>New Angle on the New Ferrari. Revisiting Affi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-15</th>\n",
       "      <td>2621267500</td>\n",
       "      <td>Those Heroes of Darfur. Tightwads and Spendth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-16</th>\n",
       "      <td>2599530000</td>\n",
       "      <td>Already an iPhone Twin?. Blogtalk: Obama's Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-17</th>\n",
       "      <td>2690270000</td>\n",
       "      <td>How Gentlemen Disagree. The Price of Oil in T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>2822430000</td>\n",
       "      <td>An Epidemic of Misunderstanding About Childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>2777480000</td>\n",
       "      <td>Raikkonen's Red Tank. The Week That Was. Nipp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-20</th>\n",
       "      <td>2698360000</td>\n",
       "      <td>Talking to Iran. 2008 Like It's All Weekend: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-21</th>\n",
       "      <td>2619240000</td>\n",
       "      <td>All the Presidents' Libraries. Bruce McLaren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-22</th>\n",
       "      <td>2540120000</td>\n",
       "      <td>Moguls Arrive, One Eye on the Sky. The View F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-23</th>\n",
       "      <td>2975070000</td>\n",
       "      <td>Google’s High-Octane Mixer. Davos Moment: How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-24</th>\n",
       "      <td>2783180000</td>\n",
       "      <td>Giuliani Is Expected to Sell His Investment B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-25</th>\n",
       "      <td>2994330000</td>\n",
       "      <td>Hedge Fund Money to Play Role in Political Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-26</th>\n",
       "      <td>2626620000</td>\n",
       "      <td>Google Guys Aren’t Writing Off Old Media. A P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-27</th>\n",
       "      <td>2661240000</td>\n",
       "      <td>Crowd Turns Out for Blair’s Not-Quite-Farewel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-28</th>\n",
       "      <td>2695860000</td>\n",
       "      <td>C.E.O.’s Drive On Thin Ice. Davos 2007 in Rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-29</th>\n",
       "      <td>2730480000</td>\n",
       "      <td>Social Entrepreneurs. \"Sunday Morning\" on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-30</th>\n",
       "      <td>2706250000</td>\n",
       "      <td>Our Secret Stash of Oil. Baker and Hamilton o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>3779500000</td>\n",
       "      <td>Silicon Valley Chiefs Notably Absent From Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-03</th>\n",
       "      <td>3818076666</td>\n",
       "      <td>Trump, Taiwan and China: The Controversy, Exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-04</th>\n",
       "      <td>3856653333</td>\n",
       "      <td>Hunting ‘Turr’ in Newfoundland’s Frigid Water...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>3895230000</td>\n",
       "      <td>Trump’s Meeting With Al Gore Gives Environmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>3855320000</td>\n",
       "      <td>Senate Republican Leaders Vow to Begin Repeal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>4501820000</td>\n",
       "      <td>Can Congress Lift the Presidential Conflict o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>4200580000</td>\n",
       "      <td>The Freaky Food Chain Behind Your Lobster Din...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-09</th>\n",
       "      <td>3884480000</td>\n",
       "      <td>Trump Spent Far Less Than Clinton, but Paid H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-10</th>\n",
       "      <td>3934490000</td>\n",
       "      <td>As Turkey Cracks Down, Kurdish Mayors Pack Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>3984500000</td>\n",
       "      <td>I.M.F. Chief Heads to Trial; Fed Is Expected ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>4034510000</td>\n",
       "      <td>Pennsylvania and Wisconsin End Election Recou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>3857590000</td>\n",
       "      <td>The Most Talked-About Debates of 2016. Wells ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>4406970000</td>\n",
       "      <td>Can Trump Get Tough With China?. The Oakland ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>4168200000</td>\n",
       "      <td>Hispanic Surnames on the Rise in U.S. as Immi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>5920340000</td>\n",
       "      <td>Vine, the Six-Second Video App, Is Not Quite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-17</th>\n",
       "      <td>5029683333</td>\n",
       "      <td>Trump’s Win Helps Carve a Path to Washington ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>4139026666</td>\n",
       "      <td>With Comic Book, Celebrities Pay Tribute to O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>3248370000</td>\n",
       "      <td>Donald Trump and the C.I.A.. Vincent Viola, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>3298780000</td>\n",
       "      <td>Can Trump's Infrastructure Plan Work?. Volksw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>2852230000</td>\n",
       "      <td>Совершенное орудие: как российская кибермощь ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>2876320000</td>\n",
       "      <td>New Ebola Vaccine Gives 100 Percent Protectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>2020550000</td>\n",
       "      <td>Flurry of Settlements Over Toxic Mortgages Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>2012182500</td>\n",
       "      <td>Jason Miller Backs Out of White House Communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>2003815000</td>\n",
       "      <td>Wielding Claims of ‘Fake News,’ Conservatives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>1995447500</td>\n",
       "      <td>When One Party Has the Governor’s Mansion and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>1987080000</td>\n",
       "      <td>Should the U.S. Embassy Be Moved From Tel Avi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>2392360000</td>\n",
       "      <td>When Finding the Right Lawyer Seems Daunting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>2336370000</td>\n",
       "      <td>Does Empathy Guide or Hinder Moral Action?. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>2670900000</td>\n",
       "      <td>Shielding Seized Assets From Corruption’s Clu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>2670900000</td>\n",
       "      <td>Terrorist Attack at Nightclub in Istanbul Kill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                prices                                           articles\n",
       "2007-01-01  2728776000   Estimates of Iraqi Civilian Deaths. Romania a...\n",
       "2007-01-02  3078968000   For Dodd, Wall Street Looms Large. Ford's Los...\n",
       "2007-01-03  3429160000   Ethics Changes Proposed for House Trips, K St...\n",
       "2007-01-04  3004460000   I Feel Bad About My Face. Bush Recycles the T...\n",
       "2007-01-05  2919400000   Macworld Bingo. Anti-Surge Protests Against M...\n",
       "2007-01-06  2867380000   In da Car at Dakar. The Macworld-C.E.S. Confl...\n",
       "2007-01-07  2815360000   BitTorrent Comes to the Television. LG&#8217;...\n",
       "2007-01-08  2763340000   That R2 Unit Is a Real Bargain. HDTV Heavy. L...\n",
       "2007-01-09  3038380000   The iPhone Rumors Are Right&#8230;Finally. Pr...\n",
       "2007-01-10  2764660000   A Ride in a Gaming Chair. More iPhone Fun Fac...\n",
       "2007-01-11  2857870000   Accounting Games. The Good Old-Fashioned Play...\n",
       "2007-01-12  2686480000   More on Black. Best and Worst of Show. Blogta...\n",
       "2007-01-13  2664742500   Sunday's Breakfast Menu: Jan. 14. 2008: Hucka...\n",
       "2007-01-14  2643005000   New Angle on the New Ferrari. Revisiting Affi...\n",
       "2007-01-15  2621267500   Those Heroes of Darfur. Tightwads and Spendth...\n",
       "2007-01-16  2599530000   Already an iPhone Twin?. Blogtalk: Obama's Pr...\n",
       "2007-01-17  2690270000   How Gentlemen Disagree. The Price of Oil in T...\n",
       "2007-01-18  2822430000   An Epidemic of Misunderstanding About Childre...\n",
       "2007-01-19  2777480000   Raikkonen's Red Tank. The Week That Was. Nipp...\n",
       "2007-01-20  2698360000   Talking to Iran. 2008 Like It's All Weekend: ...\n",
       "2007-01-21  2619240000   All the Presidents' Libraries. Bruce McLaren ...\n",
       "2007-01-22  2540120000   Moguls Arrive, One Eye on the Sky. The View F...\n",
       "2007-01-23  2975070000   Google’s High-Octane Mixer. Davos Moment: How...\n",
       "2007-01-24  2783180000   Giuliani Is Expected to Sell His Investment B...\n",
       "2007-01-25  2994330000   Hedge Fund Money to Play Role in Political Ra...\n",
       "2007-01-26  2626620000   Google Guys Aren’t Writing Off Old Media. A P...\n",
       "2007-01-27  2661240000   Crowd Turns Out for Blair’s Not-Quite-Farewel...\n",
       "2007-01-28  2695860000   C.E.O.’s Drive On Thin Ice. Davos 2007 in Rev...\n",
       "2007-01-29  2730480000   Social Entrepreneurs. \"Sunday Morning\" on the...\n",
       "2007-01-30  2706250000   Our Secret Stash of Oil. Baker and Hamilton o...\n",
       "...                ...                                                ...\n",
       "2016-12-02  3779500000   Silicon Valley Chiefs Notably Absent From Tru...\n",
       "2016-12-03  3818076666   Trump, Taiwan and China: The Controversy, Exp...\n",
       "2016-12-04  3856653333   Hunting ‘Turr’ in Newfoundland’s Frigid Water...\n",
       "2016-12-05  3895230000   Trump’s Meeting With Al Gore Gives Environmen...\n",
       "2016-12-06  3855320000   Senate Republican Leaders Vow to Begin Repeal...\n",
       "2016-12-07  4501820000   Can Congress Lift the Presidential Conflict o...\n",
       "2016-12-08  4200580000   The Freaky Food Chain Behind Your Lobster Din...\n",
       "2016-12-09  3884480000   Trump Spent Far Less Than Clinton, but Paid H...\n",
       "2016-12-10  3934490000   As Turkey Cracks Down, Kurdish Mayors Pack Ba...\n",
       "2016-12-11  3984500000   I.M.F. Chief Heads to Trial; Fed Is Expected ...\n",
       "2016-12-12  4034510000   Pennsylvania and Wisconsin End Election Recou...\n",
       "2016-12-13  3857590000   The Most Talked-About Debates of 2016. Wells ...\n",
       "2016-12-14  4406970000   Can Trump Get Tough With China?. The Oakland ...\n",
       "2016-12-15  4168200000   Hispanic Surnames on the Rise in U.S. as Immi...\n",
       "2016-12-16  5920340000   Vine, the Six-Second Video App, Is Not Quite ...\n",
       "2016-12-17  5029683333   Trump’s Win Helps Carve a Path to Washington ...\n",
       "2016-12-18  4139026666   With Comic Book, Celebrities Pay Tribute to O...\n",
       "2016-12-19  3248370000   Donald Trump and the C.I.A.. Vincent Viola, B...\n",
       "2016-12-20  3298780000   Can Trump's Infrastructure Plan Work?. Volksw...\n",
       "2016-12-21  2852230000   Совершенное орудие: как российская кибермощь ...\n",
       "2016-12-22  2876320000   New Ebola Vaccine Gives 100 Percent Protectio...\n",
       "2016-12-23  2020550000   Flurry of Settlements Over Toxic Mortgages Ma...\n",
       "2016-12-24  2012182500   Jason Miller Backs Out of White House Communi...\n",
       "2016-12-25  2003815000   Wielding Claims of ‘Fake News,’ Conservatives...\n",
       "2016-12-26  1995447500   When One Party Has the Governor’s Mansion and...\n",
       "2016-12-27  1987080000   Should the U.S. Embassy Be Moved From Tel Avi...\n",
       "2016-12-28  2392360000   When Finding the Right Lawyer Seems Daunting,...\n",
       "2016-12-29  2336370000   Does Empathy Guide or Hinder Moral Action?. C...\n",
       "2016-12-30  2670900000   Shielding Seized Assets From Corruption’s Clu...\n",
       "2016-12-31  2670900000  Terrorist Attack at Nightclub in Istanbul Kill...\n",
       "\n",
       "[3653 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>2728776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>3078968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>3429160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>3004460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>2919400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-06</th>\n",
       "      <td>2867380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-07</th>\n",
       "      <td>2815360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>2763340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>3038380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>2764660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-11</th>\n",
       "      <td>2857870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-12</th>\n",
       "      <td>2686480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-13</th>\n",
       "      <td>2664742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-14</th>\n",
       "      <td>2643005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-15</th>\n",
       "      <td>2621267500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-16</th>\n",
       "      <td>2599530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-17</th>\n",
       "      <td>2690270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>2822430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>2777480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-20</th>\n",
       "      <td>2698360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-21</th>\n",
       "      <td>2619240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-22</th>\n",
       "      <td>2540120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-23</th>\n",
       "      <td>2975070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-24</th>\n",
       "      <td>2783180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-25</th>\n",
       "      <td>2994330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-26</th>\n",
       "      <td>2626620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-27</th>\n",
       "      <td>2661240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-28</th>\n",
       "      <td>2695860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-29</th>\n",
       "      <td>2730480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-30</th>\n",
       "      <td>2706250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>3779500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-03</th>\n",
       "      <td>3818076666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-04</th>\n",
       "      <td>3856653333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>3895230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>3855320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>4501820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>4200580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-09</th>\n",
       "      <td>3884480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-10</th>\n",
       "      <td>3934490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>3984500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>4034510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>3857590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>4406970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>4168200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>5920340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-17</th>\n",
       "      <td>5029683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>4139026666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>3248370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>3298780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>2852230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>2876320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>2020550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>2012182500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>2003815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>1995447500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>1987080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>2392360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>2336370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>2670900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>2670900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                prices\n",
       "2007-01-01  2728776000\n",
       "2007-01-02  3078968000\n",
       "2007-01-03  3429160000\n",
       "2007-01-04  3004460000\n",
       "2007-01-05  2919400000\n",
       "2007-01-06  2867380000\n",
       "2007-01-07  2815360000\n",
       "2007-01-08  2763340000\n",
       "2007-01-09  3038380000\n",
       "2007-01-10  2764660000\n",
       "2007-01-11  2857870000\n",
       "2007-01-12  2686480000\n",
       "2007-01-13  2664742500\n",
       "2007-01-14  2643005000\n",
       "2007-01-15  2621267500\n",
       "2007-01-16  2599530000\n",
       "2007-01-17  2690270000\n",
       "2007-01-18  2822430000\n",
       "2007-01-19  2777480000\n",
       "2007-01-20  2698360000\n",
       "2007-01-21  2619240000\n",
       "2007-01-22  2540120000\n",
       "2007-01-23  2975070000\n",
       "2007-01-24  2783180000\n",
       "2007-01-25  2994330000\n",
       "2007-01-26  2626620000\n",
       "2007-01-27  2661240000\n",
       "2007-01-28  2695860000\n",
       "2007-01-29  2730480000\n",
       "2007-01-30  2706250000\n",
       "...                ...\n",
       "2016-12-02  3779500000\n",
       "2016-12-03  3818076666\n",
       "2016-12-04  3856653333\n",
       "2016-12-05  3895230000\n",
       "2016-12-06  3855320000\n",
       "2016-12-07  4501820000\n",
       "2016-12-08  4200580000\n",
       "2016-12-09  3884480000\n",
       "2016-12-10  3934490000\n",
       "2016-12-11  3984500000\n",
       "2016-12-12  4034510000\n",
       "2016-12-13  3857590000\n",
       "2016-12-14  4406970000\n",
       "2016-12-15  4168200000\n",
       "2016-12-16  5920340000\n",
       "2016-12-17  5029683333\n",
       "2016-12-18  4139026666\n",
       "2016-12-19  3248370000\n",
       "2016-12-20  3298780000\n",
       "2016-12-21  2852230000\n",
       "2016-12-22  2876320000\n",
       "2016-12-23  2020550000\n",
       "2016-12-24  2012182500\n",
       "2016-12-25  2003815000\n",
       "2016-12-26  1995447500\n",
       "2016-12-27  1987080000\n",
       "2016-12-28  2392360000\n",
       "2016-12-29  2336370000\n",
       "2016-12-30  2670900000\n",
       "2016-12-31  2670900000\n",
       "\n",
       "[3653 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_stocks[['prices']].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding new columns to the data frame\n",
    "df[\"compound\"] = ''\n",
    "df[\"neg\"] = ''\n",
    "df[\"neu\"] = ''\n",
    "df[\"pos\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>2728776000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>3078968000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>3429160000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>3004460000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>2919400000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-06</th>\n",
       "      <td>2867380000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-07</th>\n",
       "      <td>2815360000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>2763340000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>3038380000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>2764660000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-11</th>\n",
       "      <td>2857870000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-12</th>\n",
       "      <td>2686480000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-13</th>\n",
       "      <td>2664742500</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-14</th>\n",
       "      <td>2643005000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-15</th>\n",
       "      <td>2621267500</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-16</th>\n",
       "      <td>2599530000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-17</th>\n",
       "      <td>2690270000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-18</th>\n",
       "      <td>2822430000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-19</th>\n",
       "      <td>2777480000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-20</th>\n",
       "      <td>2698360000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-21</th>\n",
       "      <td>2619240000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-22</th>\n",
       "      <td>2540120000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-23</th>\n",
       "      <td>2975070000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-24</th>\n",
       "      <td>2783180000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-25</th>\n",
       "      <td>2994330000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-26</th>\n",
       "      <td>2626620000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-27</th>\n",
       "      <td>2661240000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-28</th>\n",
       "      <td>2695860000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-29</th>\n",
       "      <td>2730480000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-30</th>\n",
       "      <td>2706250000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-02</th>\n",
       "      <td>3779500000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-03</th>\n",
       "      <td>3818076666</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-04</th>\n",
       "      <td>3856653333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-05</th>\n",
       "      <td>3895230000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-06</th>\n",
       "      <td>3855320000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-07</th>\n",
       "      <td>4501820000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-08</th>\n",
       "      <td>4200580000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-09</th>\n",
       "      <td>3884480000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-10</th>\n",
       "      <td>3934490000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>3984500000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-12</th>\n",
       "      <td>4034510000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-13</th>\n",
       "      <td>3857590000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-14</th>\n",
       "      <td>4406970000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-15</th>\n",
       "      <td>4168200000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-16</th>\n",
       "      <td>5920340000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-17</th>\n",
       "      <td>5029683333</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-18</th>\n",
       "      <td>4139026666</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-19</th>\n",
       "      <td>3248370000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-20</th>\n",
       "      <td>3298780000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-21</th>\n",
       "      <td>2852230000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>2876320000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>2020550000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>2012182500</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>2003815000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>1995447500</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>1987080000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>2392360000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>2336370000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>2670900000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>2670900000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3653 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                prices compound neg neu pos\n",
       "2007-01-01  2728776000                     \n",
       "2007-01-02  3078968000                     \n",
       "2007-01-03  3429160000                     \n",
       "2007-01-04  3004460000                     \n",
       "2007-01-05  2919400000                     \n",
       "2007-01-06  2867380000                     \n",
       "2007-01-07  2815360000                     \n",
       "2007-01-08  2763340000                     \n",
       "2007-01-09  3038380000                     \n",
       "2007-01-10  2764660000                     \n",
       "2007-01-11  2857870000                     \n",
       "2007-01-12  2686480000                     \n",
       "2007-01-13  2664742500                     \n",
       "2007-01-14  2643005000                     \n",
       "2007-01-15  2621267500                     \n",
       "2007-01-16  2599530000                     \n",
       "2007-01-17  2690270000                     \n",
       "2007-01-18  2822430000                     \n",
       "2007-01-19  2777480000                     \n",
       "2007-01-20  2698360000                     \n",
       "2007-01-21  2619240000                     \n",
       "2007-01-22  2540120000                     \n",
       "2007-01-23  2975070000                     \n",
       "2007-01-24  2783180000                     \n",
       "2007-01-25  2994330000                     \n",
       "2007-01-26  2626620000                     \n",
       "2007-01-27  2661240000                     \n",
       "2007-01-28  2695860000                     \n",
       "2007-01-29  2730480000                     \n",
       "2007-01-30  2706250000                     \n",
       "...                ...      ...  ..  ..  ..\n",
       "2016-12-02  3779500000                     \n",
       "2016-12-03  3818076666                     \n",
       "2016-12-04  3856653333                     \n",
       "2016-12-05  3895230000                     \n",
       "2016-12-06  3855320000                     \n",
       "2016-12-07  4501820000                     \n",
       "2016-12-08  4200580000                     \n",
       "2016-12-09  3884480000                     \n",
       "2016-12-10  3934490000                     \n",
       "2016-12-11  3984500000                     \n",
       "2016-12-12  4034510000                     \n",
       "2016-12-13  3857590000                     \n",
       "2016-12-14  4406970000                     \n",
       "2016-12-15  4168200000                     \n",
       "2016-12-16  5920340000                     \n",
       "2016-12-17  5029683333                     \n",
       "2016-12-18  4139026666                     \n",
       "2016-12-19  3248370000                     \n",
       "2016-12-20  3298780000                     \n",
       "2016-12-21  2852230000                     \n",
       "2016-12-22  2876320000                     \n",
       "2016-12-23  2020550000                     \n",
       "2016-12-24  2012182500                     \n",
       "2016-12-25  2003815000                     \n",
       "2016-12-26  1995447500                     \n",
       "2016-12-27  1987080000                     \n",
       "2016-12-28  2392360000                     \n",
       "2016-12-29  2336370000                     \n",
       "2016-12-30  2670900000                     \n",
       "2016-12-31  2670900000                     \n",
       "\n",
       "[3653 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import unicodedata\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "for date, row in df_stocks.T.iteritems():\n",
    "    try:\n",
    "        sentence = unicodedata.normalize('NFKD', df_stocks.loc[date, 'articles'])\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        df.set_value(date, 'compound', ss['compound'])\n",
    "        df.set_value(date, 'neg', ss['neg'])\n",
    "        df.set_value(date, 'neu', ss['neu'])\n",
    "        df.set_value(date, 'pos', ss['pos'])\n",
    "    except TypeError:\n",
    "        print (df_stocks.loc[date, 'articles'])\n",
    "        print (date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence = 'paris shootout police officer suspected guman dead'\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# import unicodedata\n",
    "# sid = SentimentIntensityAnalyzer()\n",
    "# ss = sid.polarity_scores(sentence)\n",
    "# ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking date for empty strings\n",
    "# for date, row in df_stocks.T.iteritems():\n",
    "#     if type(df_stocks.loc[date, 'articles']).__name__ == 'str':\n",
    "#         print date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = '2007-01-01'\n",
    "train_end_date = '2015-12-31'\n",
    "test_start_date = '2016-01-01'\n",
    "test_end_date = '2017-12-31'\n",
    "train = df.ix[train_start_date : train_end_date]\n",
    "test = df.ix[test_start_date:test_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in train.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "    sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_train = np.asarray(sentiment_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in test.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "    sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_test = np.asarray(sentiment_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(train['prices'])\n",
    "y_test = pd.DataFrame(test['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(numpy_df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction, bias, contributions = ti.predict(rf, numpy_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = pd.date_range(test_start_date, test_end_date)\n",
    "predictions_df = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_df.plot() \n",
    "#test['prices'].plot()\n",
    "\n",
    "predictions_plot = predictions_df.plot()\n",
    "\n",
    "fig = y_test.plot(ax = predictions_plot).get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = predictions_df.rename(columns={\"prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices 8-2 years')\n",
    "ax.set_xlabel(\"Dates\")\n",
    "ax.set_ylabel(\"Stock Prices\")\n",
    "fig = y_test.rename(columns={\"prices\": \"actual_price\"}).plot(ax = ax).get_figure()\n",
    "# colors = ['332288', '88CCEE', '44AA99', '117733', '999933', 'DDCC77', 'CC6677', '882255', 'AA4499']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the prices by a constant value so that it represents closing price during the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "temp_date = test_start_date\n",
    "average_last_5_days_test = 0\n",
    "total_days = 10\n",
    "for i in range(total_days):\n",
    "    average_last_5_days_test += test.loc[temp_date, 'prices']\n",
    "    # Converting string to date time\n",
    "    temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "    # Reducing one day from date time\n",
    "    difference = temp_date + timedelta(days=1)\n",
    "    # Converting again date time to string\n",
    "    temp_date = difference.strftime('%Y-%m-%d')\n",
    "    #print temp_date\n",
    "average_last_5_days_test = average_last_5_days_test / total_days\n",
    "print (average_last_5_days_test)\n",
    "\n",
    "temp_date = test_start_date\n",
    "average_upcoming_5_days_predicted = 0\n",
    "for i in range(total_days):\n",
    "    average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "    # Converting string to date time\n",
    "    temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "    # Adding one day from date time\n",
    "    difference = temp_date + timedelta(days=1)\n",
    "    # Converting again date time to string\n",
    "    temp_date = difference.strftime('%Y-%m-%d')\n",
    "    print (temp_date)\n",
    "average_upcoming_5_days_predicted = average_upcoming_5_days_predicted / total_days\n",
    "print (average_upcoming_5_days_predicted)\n",
    "#average train.loc['2013-12-31', 'prices'] - advpredictions_df.loc['2014-01-01', 'prices']\n",
    "difference_test_predicted_prices = average_last_5_days_test - average_upcoming_5_days_predicted\n",
    "print (difference_test_predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 6177 to all the advpredictions_df price values\n",
    "predictions_df['prices'] = predictions_df['prices'] + difference_test_predicted_prices\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = predictions_df.rename(columns={\"prices\": \"predicted_price\"}).plot(title='Random Forest predicted prices 8-2 years after aligning')\n",
    "ax.set_xlabel(\"Dates\")\n",
    "ax.set_ylabel(\"Stock Prices\")\n",
    "fig = y_test.rename(columns={\"prices\": \"actual_price\"}).plot(ax = ax).get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing the time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying EWMA pandas to smooth the stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['ewma'] = pd.ewma(predictions_df[\"prices\"], span=60, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df['actual_value'] = test['prices']\n",
    "predictions_df['actual_value_ewma'] = pd.ewma(predictions_df[\"actual_value\"], span=60, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Changing column names\n",
    "predictions_df.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plotting test predictions after smoothing\n",
    "predictions_plot = predictions_df.plot(title='Random Forest predicted prices 8-2 years after aligning & smoothing')\n",
    "predictions_plot.set_xlabel(\"Dates\")\n",
    "predictions_plot.set_ylabel(\"Stock Prices\")\n",
    "fig = predictions_plot.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting just predict and actual average curves\n",
    "predictions_df_average = predictions_df[['average_predicted_price', 'average_actual_price']]\n",
    "predictions_plot = predictions_df_average.plot(title='Random Forest 8-2 years after aligning & smoothing')\n",
    "predictions_plot.set_xlabel(\"Dates\")\n",
    "predictions_plot.set_ylabel(\"Stock Prices\")\n",
    "fig = predictions_plot.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing the prices by a constant value so that it represents closing price during the testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def offset_value(test_start_date, test, predictions_df):\n",
    "    temp_date = test_start_date\n",
    "    average_last_5_days_test = 0\n",
    "    average_upcoming_5_days_predicted = 0\n",
    "    total_days = 10\n",
    "    for i in range(total_days):\n",
    "        average_last_5_days_test += test.loc[temp_date, 'prices']\n",
    "        temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "        difference = temp_date + timedelta(days=1)\n",
    "        temp_date = difference.strftime('%Y-%m-%d')\n",
    "    average_last_5_days_test = average_last_5_days_test / total_days\n",
    "\n",
    "    temp_date = test_start_date\n",
    "    for i in range(total_days):\n",
    "        average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "        temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "        difference = temp_date + timedelta(days=1)\n",
    "        temp_date = difference.strftime('%Y-%m-%d')\n",
    "    average_upcoming_5_days_predicted = average_upcoming_5_days_predicted / total_days\n",
    "    difference_test_predicted_prices = average_last_5_days_test - average_upcoming_5_days_predicted\n",
    "    return difference_test_predicted_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "# # Converting string to date time\n",
    "# temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "# # Adding one day from date time\n",
    "# difference = temp_date + timedelta(days=1)\n",
    "# # Converting again date time to string\n",
    "# temp_date = difference.strftime('%Y-%m-%d')\n",
    "        \n",
    "# start_year = datetime.strptime(train_start_date, \"%Y-%m-%d\").date().month\n",
    "\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-12-31'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(numpy_df_train, train['prices'])\n",
    "    \n",
    "\n",
    "    prediction = lr.predict(numpy_df_test)\n",
    "    prediction_list.append(prediction)\n",
    "    #print train_start_date + ' ' + train_end_date + ' ' + test_start_date + ' ' + test_end_date\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    #print year\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=10, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=10, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    predictions_df_list.plot()\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    predictions_df_list_average.plot()\n",
    "    \n",
    "#     predictions_df_list.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "# # Converting string to date time\n",
    "# temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "# # Adding one day from date time\n",
    "# difference = temp_date + timedelta(days=1)\n",
    "# # Converting again date time to string\n",
    "# temp_date = difference.strftime('%Y-%m-%d')\n",
    "# start_year = datetime.strptime(train_start_date, \"%Y-%m-%d\").date().month\n",
    "\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-12-31'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    rf = RandomForestRegressor(random_state=665)\n",
    "    rf.fit(numpy_df_train, train['prices'])\n",
    "    #print rf\n",
    "    \n",
    "    prediction, bias, contributions = ti.predict(rf, numpy_df_test)\n",
    "    prediction_list.append(prediction)\n",
    "    #print train_start_date + ' ' + train_end_date + ' ' + test_start_date + ' ' + test_end_date\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    #print year\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=10, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=10, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    predictions_df_list.plot()\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    predictions_df_list_average.plot()\n",
    "    \n",
    "#     predictions_df_list.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image  \n",
    "# dot_data = tree.export_graphviz(rf, out_file=None, \n",
    "#                      feature_names=['comp', 'neg', 'neu', 'pos'],  \n",
    "#                      class_names=iris.target_names,  \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# average_upcoming_5_days_predicted += predictions_df.loc[temp_date, 'prices']\n",
    "# # Converting string to date time\n",
    "# temp_date = datetime.strptime(temp_date, \"%Y-%m-%d\").date()\n",
    "# # Adding one day from date time\n",
    "# difference = temp_date + timedelta(days=1)\n",
    "# # Converting again date time to string\n",
    "# temp_date = difference.strftime('%Y-%m-%d')\n",
    "        \n",
    "# start_year = datetime.strptime(train_start_date, \"%Y-%m-%d\").date().month\n",
    "\n",
    "years = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
    "prediction_list = []\n",
    "for year in years:\n",
    "    # Splitting the training and testing data\n",
    "    train_start_date = str(year) + '-01-01'\n",
    "    train_end_date = str(year) + '-10-31'\n",
    "    test_start_date = str(year) + '-11-01'\n",
    "    test_end_date = str(year) + '-12-31'\n",
    "    train = df.ix[train_start_date : train_end_date]\n",
    "    test = df.ix[test_start_date:test_end_date]\n",
    "    \n",
    "    # Calculating the sentiment score\n",
    "    sentiment_score_list = []\n",
    "    for date, row in train.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_train = np.asarray(sentiment_score_list)\n",
    "    sentiment_score_list = []\n",
    "    for date, row in test.T.iteritems():\n",
    "        sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "        #sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "    numpy_df_test = np.asarray(sentiment_score_list)\n",
    "    \n",
    "    # Generating models\n",
    "    mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False) # span = 20 # best 1\n",
    "    mlpc.fit(numpy_df_train, train['prices'])   \n",
    "    prediction = mlpc.predict(numpy_df_test)\n",
    "    prediction_list.append(prediction)\n",
    "    #print train_start_date + ' ' + train_end_date + ' ' + test_start_date + ' ' + test_end_date\n",
    "    idx = pd.date_range(test_start_date, test_end_date)\n",
    "    #print year\n",
    "    predictions_df_list = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "    \n",
    "    difference_test_predicted_prices = offset_value(test_start_date, test, predictions_df_list)\n",
    "    # Adding offset to all the advpredictions_df price values\n",
    "    predictions_df_list['prices'] = predictions_df_list['prices'] + difference_test_predicted_prices\n",
    "    predictions_df_list\n",
    "\n",
    "    # Smoothing the plot\n",
    "    predictions_df_list['ewma'] = pd.ewma(predictions_df_list[\"prices\"], span=20, freq=\"D\")\n",
    "    predictions_df_list['actual_value'] = test['prices']\n",
    "    predictions_df_list['actual_value_ewma'] = pd.ewma(predictions_df_list[\"actual_value\"], span=20, freq=\"D\")\n",
    "    # Changing column names\n",
    "    predictions_df_list.columns = ['predicted_price', 'average_predicted_price', 'actual_price', 'average_actual_price']\n",
    "    predictions_df_list.plot()\n",
    "    predictions_df_list_average = predictions_df_list[['average_predicted_price', 'average_actual_price']]\n",
    "    predictions_df_list_average.plot()\n",
    "    \n",
    "#     predictions_df_list.show()\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "filename = 'finalized_model_GSPC.sav'\n",
    "pickle.dump(mlpc, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='tanh', \n",
    "                         solver='lbfgs', alpha=0.010, learning_rate_init = 0.001, shuffle=False)\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.010, learning_rate_init = 0.001, shuffle=False) # span = 20\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 100), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False) # span = 20 # best 1\n",
    "mlpc = MLPClassifier(hidden_layer_sizes=(100, 200, 50), activation='relu', \n",
    "                         solver='lbfgs', alpha=0.005, learning_rate_init = 0.001, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the performance of training data itself\n",
    "prediction, bias, contributions = ti.predict(rf, numpy_df_train)\n",
    "idx = pd.date_range(train_start_date, train_end_date)\n",
    "predictions_df1 = pd.DataFrame(data=prediction[0:], index = idx, columns=['prices'])\n",
    "predictions_df1.plot() \n",
    "train['prices'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#filename = 'finalized_model.sav'\n",
    "#pickle.dump(mlpc, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(test,)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
